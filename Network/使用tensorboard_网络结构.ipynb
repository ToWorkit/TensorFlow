{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 手写数字相关工具包\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "# 没有的话会自动去下载数据集\n",
    "# 数据路径  转为one_hot(某一位数字为1，其余数字都为0)格式\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# 每个批次的大小\n",
    "'''\n",
    "优化\n",
    "    可修改批次大小\n",
    "    可添加隐藏层\n",
    "'''\n",
    "# 每次放入批次大小的数据集\n",
    "# 形式为矩阵\n",
    "batch_size = 100\n",
    "# 批次的个数\n",
    "# 计算一共有多少个批次\n",
    "# 总训练集  整除  批次大小\n",
    "n_batch = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iter)第\t0\t个周期(Testing Accuracy)准确率\t0.8243\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "可视化命名空间\n",
    "'''\n",
    "with tf.name_scope('input'):\n",
    "    # 输入\n",
    "    # 定义两个placeholder\n",
    "    # [行 -> 任意值(此处为100，与上面的批次大小一致), 列 -> 每张图片都是28*28，需要转为一维的向量也就是28*28=784]\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x_input')\n",
    "    # 数字为 0-9 \n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y_input')\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    # 输出\n",
    "    # 创建简单的神经网络\n",
    "    '''\n",
    "    可修改初始值 ?\n",
    "    '''\n",
    "    with tf.name_scope('weights'):\n",
    "        # 权值 -> 当前权值 784个输入层， 10个输出层\n",
    "        W = tf.Variable(tf.zeros([784,10]), name='W')\n",
    "    with tf.name_scope('biases'):\n",
    "        # 偏置值\n",
    "        b = tf.Variable(tf.zeros([10]), name='b')\n",
    "    # 信号和    \n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x, W) + b\n",
    "    # 预测值\n",
    "    # 激活函数 -> 需用softmax函数\n",
    "    # 数据和权值矩阵相乘 + 偏置值 再 使用softmax函数激活\n",
    "    # softmax -> 转换为概率值\n",
    "    with tf.name_scope('softmax'):\n",
    "        # 预测值\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "# 优化\n",
    "'''\n",
    "可选择优化方式，比如交叉熵\n",
    "'''\n",
    "    # 二次代价函数\n",
    "    # 误差值\n",
    "    # 真实值 - 预测值 的 平方 的 平均值\n",
    "    # loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "with tf.name_scope('loss'):\n",
    "    # softmax交叉熵代价函数\n",
    "    # params => 标签值(真实值)， 预测值   \n",
    "    # reduce_mean -> 平均值\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# 梯度下降法优化 loss\n",
    "''' \n",
    "学习率可修改\n",
    "'''\n",
    "with tf.name_scope('train'):\n",
    "    # 0.2的学习率最小化loss\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        # 测试准确率 => 存放布尔值的列表\n",
    "        # tf.equal -> 比较参数一(真实值数据)和参数二(预测值数据)行[或者列]的最大值 => True or False\n",
    "        # argmax -> 返回一维张量中最大值所在的位置\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        # 求准确率\n",
    "        # tf.cast -> 将对比后的布尔值列表转换为对应的浮点值 => True为1.0，False为0\n",
    "        # tf.reduce_mean -> 平均值\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 先初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    '''\n",
    "    画 params => 路径, 图结构(graph)\n",
    "    '''\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    # 21个周期\n",
    "    # 图片训练 21 个周期\n",
    "    for epoch in range(1):\n",
    "        # 批次\n",
    "        # 所有的图片都训练一次\n",
    "        for batch in range(n_batch):\n",
    "            # batch_xs\n",
    "            # 获得一个批次，每次大小为100\n",
    "            # 相当于每次获取100张图片\n",
    "            # batch_ys\n",
    "            # 图片的标签\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 执行训练传入数据\n",
    "            sess.run(train_step,feed_dict={x:batch_xs, y:batch_ys})\n",
    "        # 每个周期的准确率\n",
    "        # 测试集的图片和测试集的图片标签\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print('(Iter)第\\t%s\\t个周期(Testing Accuracy)准确率\\t%s' % (str(epoch), str(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

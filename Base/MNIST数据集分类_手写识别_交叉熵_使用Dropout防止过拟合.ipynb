{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防止过拟合\n",
    "# Dropout -> 迭代过程中使得部分神经元工作，部分神经元不工作，每迭代一次就更换一次\n",
    "import tensorflow as tf\n",
    "# 手写数字相关工具包\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 样本\n",
    "# 载入数据集\n",
    "# 没有的话会自动去下载数据集\n",
    "# 数据路径  转为one_hot(某一位数字为1，其余数字都为0)格式\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# 每个批次的大小\n",
    "'''\n",
    "优化\n",
    "    可修改批次大小\n",
    "    可添加隐藏层\n",
    "'''\n",
    "# 每次放入批次大小的数据集\n",
    "# 形式为矩阵\n",
    "batch_size = 100\n",
    "# 批次的个数\n",
    "# 计算一共有多少个批次\n",
    "# 总训练集  整除  批次大小\n",
    "n_batch = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入层\n",
    "# 定义两个placeholder\n",
    "# [行 -> 任意值(此处为100，与上面的批次大小一致), 列 -> 每张图片都是28*28，需要转为一维的向量也就是28*28=784]\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# 数字为 0-9 \n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "'''\n",
    "增加一个输入，用来设置Dropout的参数\n",
    "'''\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建简单的神经网络\n",
    "\n",
    "# 隐藏层(中间层)\n",
    "# # 都初始化为 0 tf.zeros，并不是很好\n",
    "# '''\n",
    "# 可修改初始值 ?\n",
    "# '''\n",
    "# # 权值 -> 当前权值 784个输入层， 10个输出层\n",
    "# W = tf.Variable(tf.zeros([784,10]))\n",
    "# # 偏置值\n",
    "# # 真实值\n",
    "# b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "'''\n",
    "初始化权值\n",
    "'''\n",
    "# 截断的正态分布， param => (限制值(784 - 2000个神经元)， 标准差为0.1)\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 2000],stddev=0.1))\n",
    "# 偏置值\n",
    "b1 = tf.Variable(tf.zeros([2000]) + 0.1)\n",
    "# 隐藏层输出\n",
    "# 使用双曲正切函数激活\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "# 防止过拟合 -> Dropout\n",
    "# param => (某一层的输出， 设置参数(%) -> 代表有多少神经元是工作的 1 => 100% 0.5 => 50%)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "'''\n",
    "继续添加隐藏层的神经网络元是为了测试过拟合\n",
    "'''\n",
    "# 截断的正态分布， param => (限制值， 标准差为0.1)\n",
    "W2 = tf.Variable(tf.truncated_normal([2000, 2000],stddev=0.1))\n",
    "# 偏置值\n",
    "b2 = tf.Variable(tf.zeros([2000]) + 0.1)\n",
    "# 隐藏层输出\n",
    "# 使用双曲正切函数激活\n",
    "# tf.matmul(L1_drop, W2) -> 信号总和 连接 上一个隐藏层\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)\n",
    "# 防止过拟合 -> Dropout\n",
    "# param => (某一层的输出， 设置参数(%) -> 代表有多少神经元是工作的 1 => 100% 0.5 => 50%)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "# 截断的正态分布， param => (限制值， 标准差为0.1)\n",
    "W3 = tf.Variable(tf.truncated_normal([2000, 1000],stddev=0.1))\n",
    "# 偏置值\n",
    "b3 = tf.Variable(tf.zeros([1000]) + 0.1)\n",
    "# 隐藏层输出\n",
    "# 使用双曲正切函数激活\n",
    "# tf.matmul(L2_drop, W3) -> 信号总和 连接 上一个隐藏层\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop, W3) + b3)\n",
    "# 防止过拟合 -> Dropout\n",
    "# param => (某一层的输出， 设置参数(%) -> 代表有多少神经元是工作的 1 => 100% 0.5 => 50%)\n",
    "L3_drop = tf.nn.dropout(L3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出层\n",
    "'''\n",
    "初始化权值\n",
    "'''\n",
    "# 截断的正态分布， param => (限制值， 标准差为0.1)\n",
    "# 从截断的正态分布中输出随机值\n",
    "W4 = tf.Variable(tf.truncated_normal([1000, 10],stddev=0.1))\n",
    "# 偏置值\n",
    "b4 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "# 预测值\n",
    "# 激活函数 -> 需用softmax函数\n",
    "# 数据和权值矩阵相乘 + 偏置值 再 使用softmax函数激活\n",
    "# softmax -> 转换为概率值\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4) + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化\n",
    "'''\n",
    "可选择优化方式，比如交叉熵\n",
    "'''\n",
    "# 二次代价函数\n",
    "# 误差值\n",
    "# 真实值 - 预测值 的 平方 的 平均值\n",
    "# loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "\n",
    "# softmax交叉熵\n",
    "# 标签值(真实值), 预测值  平均值\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "# 梯度下降 \n",
    "''' \n",
    "学习率可修改\n",
    "'''\n",
    "# 0.2的学习率最小化loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "# 测试准确率 => 存放布尔值的列表\n",
    "# tf.equal -> 比较参数一(真实值数据)和参数二(预测值数据)行[或者列]的最大值 => True or False\n",
    "# argmax -> 返回一维张量中最大值所在的位置\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "# 求准确率\n",
    "# tf.cast -> 将对比后的布尔值列表转换为对应的浮点值 => True为1.0，False为0\n",
    "# tf.reduce_mean -> 平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iter)第\t0\t个周期(Testing Accuracy)测试准确率\t0.9178\t(Testing Accuracy)训练准确率\t0.9122\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6b6be99e2849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# 启用Dropout传入0.7 -> 70%的神经元参与训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m# 结果分析使用Dropout可以使测试准确率和训练准确率的差距缩小\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# 两类数据，一类测试集， 一类训练集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# 测试模型的好坏使用测试集数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\just do it\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\just do it\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\just do it\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\users\\just do it\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\just do it\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 先初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 21个周期\n",
    "    # 图片训练 21 个周期\n",
    "    for epoch in range(31):\n",
    "        # 批次\n",
    "        # 所有的图片都训练一次\n",
    "        for batch in range(n_batch):\n",
    "            # batch_xs\n",
    "            # 获得一个批次，每次大小为100\n",
    "            # 相当于每次获取100张图片\n",
    "            # batch_ys\n",
    "            # 图片的标签\n",
    "            # 训练时使用训练集数据\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 执行训练传入数据\n",
    "#             sess.run(train_step,feed_dict={x:batch_xs, y:batch_ys,keep_prob:1.0})\n",
    "            # 启用Dropout传入0.7 -> 70%的神经元参与训练\n",
    "            # 结果分析使用Dropout可以使测试准确率和训练准确率的差距缩小\n",
    "            sess.run(train_step,feed_dict={x:batch_xs, y:batch_ys,keep_prob:0.7})\n",
    "        # 两类数据，一类测试集， 一类训练集    \n",
    "        # 测试模型的好坏使用测试集数据\n",
    "        # 每个周期的准确率\n",
    "        # 测试集的图片和测试集的图片标签\n",
    "#         test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images, y:mnist.test.labels,keep_prob:1.0})\n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images, y:mnist.test.labels,keep_prob:0.7})\n",
    "        # 训练集\n",
    "        # 训练时使用到的数据\n",
    "#         train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images, y:mnist.train.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images, y:mnist.train.labels,keep_prob:0.7})\n",
    "        print('(Iter)第\\t%s\\t个周期(Testing Accuracy)测试准确率\\t%s\\t(Testing Accuracy)训练准确率\\t%s\\t' % (str(epoch), str(test_acc), str(train_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第七个周期比较重要\n",
    "\n",
    "# 二次代价函数作优化\n",
    "'''\n",
    "(Iter)第\t0\t个周期(Testing Accuracy)准确率\t0.8312\n",
    "(Iter)第\t1\t个周期(Testing Accuracy)准确率\t0.8719\n",
    "(Iter)第\t2\t个周期(Testing Accuracy)准确率\t0.8813\n",
    "(Iter)第\t3\t个周期(Testing Accuracy)准确率\t0.889\n",
    "(Iter)第\t4\t个周期(Testing Accuracy)准确率\t0.8948\n",
    "(Iter)第\t5\t个周期(Testing Accuracy)准确率\t0.8974\n",
    "(Iter)第\t6\t个周期(Testing Accuracy)准确率\t0.8995\n",
    "(Iter)第\t7\t个周期(Testing Accuracy)准确率\t0.9028\n",
    "(Iter)第\t8\t个周期(Testing Accuracy)准确率\t0.9029\n",
    "(Iter)第\t9\t个周期(Testing Accuracy)准确率\t0.9053\n",
    "(Iter)第\t10\t个周期(Testing Accuracy)准确率\t0.9066\n",
    "(Iter)第\t11\t个周期(Testing Accuracy)准确率\t0.9077\n",
    "(Iter)第\t12\t个周期(Testing Accuracy)准确率\t0.9075\n",
    "(Iter)第\t13\t个周期(Testing Accuracy)准确率\t0.9092\n",
    "(Iter)第\t14\t个周期(Testing Accuracy)准确率\t0.9101\n",
    "(Iter)第\t15\t个周期(Testing Accuracy)准确率\t0.9108\n",
    "(Iter)第\t16\t个周期(Testing Accuracy)准确率\t0.9116\n",
    "(Iter)第\t17\t个周期(Testing Accuracy)准确率\t0.9126\n",
    "(Iter)第\t18\t个周期(Testing Accuracy)准确率\t0.9128\n",
    "(Iter)第\t19\t个周期(Testing Accuracy)准确率\t0.9139\n",
    "(Iter)第\t20\t个周期(Testing Accuracy)准确率\t0.9141\n",
    "'''\n",
    "# softmax交叉熵函数\n",
    "'''\n",
    "(Iter)第\t0\t个周期(Testing Accuracy)准确率\t0.8253\n",
    "(Iter)第\t1\t个周期(Testing Accuracy)准确率\t0.8876\n",
    "(Iter)第\t2\t个周期(Testing Accuracy)准确率\t0.8997\n",
    "(Iter)第\t3\t个周期(Testing Accuracy)准确率\t0.9054\n",
    "(Iter)第\t4\t个周期(Testing Accuracy)准确率\t0.908\n",
    "(Iter)第\t5\t个周期(Testing Accuracy)准确率\t0.9099\n",
    "(Iter)第\t6\t个周期(Testing Accuracy)准确率\t0.9127\n",
    "(Iter)第\t7\t个周期(Testing Accuracy)准确率\t0.9122\n",
    "(Iter)第\t8\t个周期(Testing Accuracy)准确率\t0.9149\n",
    "(Iter)第\t9\t个周期(Testing Accuracy)准确率\t0.9161\n",
    "(Iter)第\t10\t个周期(Testing Accuracy)准确率\t0.9172\n",
    "(Iter)第\t11\t个周期(Testing Accuracy)准确率\t0.9185\n",
    "(Iter)第\t12\t个周期(Testing Accuracy)准确率\t0.918\n",
    "(Iter)第\t13\t个周期(Testing Accuracy)准确率\t0.9186\n",
    "(Iter)第\t14\t个周期(Testing Accuracy)准确率\t0.9195\n",
    "(Iter)第\t15\t个周期(Testing Accuracy)准确率\t0.9194\n",
    "(Iter)第\t16\t个周期(Testing Accuracy)准确率\t0.9209\n",
    "(Iter)第\t17\t个周期(Testing Accuracy)准确率\t0.9211\n",
    "(Iter)第\t18\t个周期(Testing Accuracy)准确率\t0.9212\n",
    "(Iter)第\t19\t个周期(Testing Accuracy)准确率\t0.9214\n",
    "(Iter)第\t20\t个周期(Testing Accuracy)准确率\t0.922\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
